nohup python -m torch.distributed.launch --nproc_per_node=8 --master_port=29501  fmow_finetune.py   --batch_size 7 \
--accum_iter 8 --epochs 50 --blr 1e-3 --layer_decay 0.75 --weight_decay 0.05 --drop_path 0.2 --reprob 0.25 \
--num_workers 8 --input_size 96 --patch_size 8 --save_every 1  \
--finetune /atlas/u/yzcong/samar/mae/sentinel_pretrain_group_c_indp_mask_drop0910_96p8_cont/checkpoint-50.pth \
--dropped_bands 0 9 10 --nb_classes 19 --model_type group_c --output_dir ./bigearthnet_finetune --dist_eval \
--log_dir ./bigearthnet_finetune --wandb bigearthnet_ms > bigearthnet_finetune.out 2>&1  &


nohup python -m torch.distributed.launch --nproc_per_node=8 --master_port=29501  fmow_finetune.py   --batch_size 7 \
--accum_iter 8 --epochs 50 --blr 1e-3 --layer_decay 0.75 --weight_decay 0.05 --drop_path 0.2 --reprob 0.25 \
--num_workers 8 --input_size 96 --patch_size 8 --save_every 1  \
--dropped_bands 0 9 10 --nb_classes 19 --model_type group_c --output_dir ./bigearthnet_scratch --dist_eval \
--log_dir ./bigearthnet_scratch --wandb bigearthnet_ms > bigearthnet_scratch.out 2>&1  &

nohup python -m torch.distributed.launch --nproc_per_node=8 --master_port=29501  fmow_finetune.py   --batch_size 7 \
--accum_iter 8 --epochs 50 --blr 1e-4 --layer_decay 0.75 --weight_decay 0.05 --drop_path 0.2 --reprob 0.25 \
--num_workers 8 --input_size 96 --patch_size 8 --save_every 1  \
--finetune /atlas/u/yzcong/samar/mae/sentinel_pretrain_group_c_indp_mask_drop0910_96p8_cont/checkpoint-50.pth \
--dropped_bands 0 9 10 --nb_classes 19 --model_type group_c --output_dir ./bigearthnet_finetune2 --dist_eval \
--log_dir ./bigearthnet_finetune2 --wandb bigearthnet_ms > bigearthnet_finetune2.out 2>&1  &




python -m torch.distributed.launch --nproc_per_node=1 --master_port=40400  fmow_finetune.py   --batch_size 1 \
--accum_iter 8 --epochs 50 --blr 1e-3 --layer_decay 0.75 --weight_decay 0.05 --drop_path 0.2 --reprob 0.25 \
--num_workers 8 --input_size 96 --patch_size 8 --save_every 1  \
--dropped_bands 0 9 10 --nb_classes 19 --model_type group_c --output_dir ./bigearthnet_test --dist_eval \
--log_dir ./bigearthnet_test



nohup python -m torch.distributed.launch --nproc_per_node=8 --master_port=29501  fmow_finetune.py   --batch_size 7 \
--accum_iter 8 --epochs 200 --blr 1e-3 --layer_decay 0.75 --weight_decay 0.05 --drop_path 0.2 --reprob 0.25 \
--num_workers 8 --input_size 96 --patch_size 8 --save_every 1  \
--resume /home/yzcong/mae/bigearthnet_finetune/checkpoint-4.pth \
--dropped_bands 0 9 10 --nb_classes 19 --model_type group_c --output_dir ./bigearthnet_finetune_contbige --dist_eval \
--log_dir ./bigearthnet_finetune_contbige --wandb bigearthnet_ms > bigearthnet_finetune_contbige.out 2>&1  &